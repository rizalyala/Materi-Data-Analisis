{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a43aa293-61de-4282-b62e-a210c9e54608",
   "metadata": {},
   "source": [
    "Data Pre-processing: Handling Missing Value - Part 1\n",
    "--\n",
    "Setelah kita melakukan eksplorasi data, kita akan melanjutkan ke tahap data pre-processing. Seperti yang saya jelaskan sebelumnya, raw data kita belum tentu bisa langsung digunakan untuk pemodelan. Jika kita memiliki banyak missing value, maka akan mengurangi performansi model dan juga beberapa algorithm machine learning tidak dapat memproses data dengan missing value. Oleh karena itu, kita perlu mengecek apakah terdapat missing value dalam data atau tidak. Jika tidak, maka kita tidak perlu melakukan apa-apa dan bisa melanjutkan ke tahap berikutnya. Jika ada, maka kita perlu melakukan treatment khusus untuk missing value ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a110348a-24a0-482a-bb1c-3b6647078510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking missing value for each feature:\n",
      "Administrative             14\n",
      "Administrative_Duration    14\n",
      "Informational              14\n",
      "Informational_Duration     14\n",
      "ProductRelated             14\n",
      "ProductRelated_Duration    14\n",
      "BounceRates                14\n",
      "ExitRates                  14\n",
      "PageValues                  0\n",
      "SpecialDay                  0\n",
      "Month                       0\n",
      "OperatingSystems            0\n",
      "Browser                     0\n",
      "Region                      0\n",
      "TrafficType                 0\n",
      "VisitorType                 0\n",
      "Weekend                     0\n",
      "Revenue                     0\n",
      "dtype: int64\n",
      "\n",
      "Counting total missing value:\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/pythonTutorial/online_raw.csv')\n",
    "\n",
    "#checking missing value for each feature  \n",
    "print('Checking missing value for each feature:')\n",
    "print(dataset.isnull().sum())\n",
    "#Counting total missing value\n",
    "print('\\nCounting total missing value:')\n",
    "print(dataset.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac83bd7-abfb-4d73-8124-56b1056a7fe6",
   "metadata": {},
   "source": [
    "Data Pre-processing: Handling Missing Value - Part 2\n",
    "--\n",
    "\n",
    "Ada beberapa metode yang dapat kita lakukan untuk menangani missing value,  menghapus data adalah salah satunya. Tetapi, metode ini tidak dapat serta merta diimplementasikan. Kita juga perlu menganalisis penyebaran missing value, dan berapa persen jumlah missing value dalam data kita,\n",
    "\n",
    "Metode ini dapat diterapkan jika tidak banyak missing value dalam data, sehingga walaupun data point ini dihapus, kita masih memiliki sejumlah data yang cukup untuk melatih model Machine Learning. Tetapi jika kita memiliki banyak missing value dan tersebar di setiap variabel, maka metode menghapus missing value tidak dapat digunakan. Kita akan kehilangan sejumlah data yang tentunya mempengaruhi performansi model. Kita bisa menghapus data point yang memiliki missing value dengan fungsi .dropna( ) dari pandas library. Fungsi dropna( ) akan menghapus data point atau baris yang memiliki missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea283a3-d246-4de6-b1e5-2d4d05d6434a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran dataset_clean: (12316, 18)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/pythonTutorial/online_raw.csv')\n",
    "\n",
    "#Drop rows with missing value   \n",
    "dataset_clean = dataset.dropna() \n",
    "print('Ukuran dataset_clean:', dataset_clean.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579d8232-8905-4c3a-ba87-f3b6dbb3685a",
   "metadata": {},
   "source": [
    "Data Pre-processing: Handling Missing Value - Part 3\n",
    "---\n",
    "\n",
    "Kita bisa menggunakan metode inpute missing value, yaitu mengisi record yang hilang ini dengan suatu nilai. Ada berbagai teknik dalam metode imputing, mulai dari yang paling sederhana yaitu mengisi missing value dengan nilai mean, median, modus, atau nilai konstan, sampai teknik paling advance yaitu dengan menggunakan nilai yang diestimasi oleh suatu predictive model. Untuk kasus ini, kita akan menggunakan imputing sederhana yaitu menggunakan nilai rataan atau mean,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0becb739-0512-467a-87bc-c4239d244b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before imputation:\n",
      "Administrative             14\n",
      "Administrative_Duration    14\n",
      "Informational              14\n",
      "Informational_Duration     14\n",
      "ProductRelated             14\n",
      "ProductRelated_Duration    14\n",
      "BounceRates                14\n",
      "ExitRates                  14\n",
      "PageValues                  0\n",
      "SpecialDay                  0\n",
      "Month                       0\n",
      "OperatingSystems            0\n",
      "Browser                     0\n",
      "Region                      0\n",
      "TrafficType                 0\n",
      "VisitorType                 0\n",
      "Weekend                     0\n",
      "Revenue                     0\n",
      "dtype: int64\n",
      "112\n",
      "\n",
      "After imputation:\n",
      "Administrative             0\n",
      "Administrative_Duration    0\n",
      "Informational              0\n",
      "Informational_Duration     0\n",
      "ProductRelated             0\n",
      "ProductRelated_Duration    0\n",
      "BounceRates                0\n",
      "ExitRates                  0\n",
      "PageValues                 0\n",
      "SpecialDay                 0\n",
      "Month                      0\n",
      "OperatingSystems           0\n",
      "Browser                    0\n",
      "Region                     0\n",
      "TrafficType                0\n",
      "VisitorType                0\n",
      "Weekend                    0\n",
      "Revenue                    0\n",
      "dtype: int64\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yala\\AppData\\Local\\Temp/ipykernel_4052/1175221403.py:12: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dataset.fillna(dataset.mean(), inplace = True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/pythonTutorial/online_raw.csv')\n",
    "\n",
    "print(\"Before imputation:\")\n",
    "# Checking missing value for each feature  \n",
    "print(dataset.isnull().sum())\n",
    "# Counting total missing value  \n",
    "print(dataset.isnull().sum().sum())\n",
    "\n",
    "print(\"\\nAfter imputation:\")\n",
    "# Fill missing value with mean of feature value  \n",
    "dataset.fillna(dataset.mean(), inplace = True)\n",
    "# Checking missing value for each feature  \n",
    "print(dataset.isnull().sum())\n",
    "# Counting total missing value  \n",
    "print(dataset.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ccb01-7f1c-4f74-a60c-82f0fb5afdf1",
   "metadata": {},
   "source": [
    "Data Preprocessing: Scaling\n",
    "---\n",
    "\n",
    "Beberapa machine learning seperti K-NN dan gradient descent mengharuskan semua variabel memiliki rentang nilai yang sama, karena jika tidak sama, feature dengan rentang nilai terbesar misalnya ProductRelated_Duration otomatis akan menjadi feature yang paling mendominasi dalam proses training/komputasi, sehingga model yang dihasilkan pun akan sangat bias. Oleh karena itu, sebelum memulai training model, kita terlebih dahulu perlu melakukan data rescaling ke dalam rentang 0 dan 1, sehingga semua feature berada dalam rentang nilai tersebut, yaitu nilai max = 1 dan nilai min = 0. Data rescaling ini dengan mudah dapat dilakukan di Python menggunakan .MinMaxScaler( ) dari Scikit-Learn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b7bf05-afe9-40c4-9817-a01b104dfa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yala\\AppData\\Local\\Temp/ipykernel_4052/1547432527.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dataset.fillna(dataset.mean(), inplace = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         min  max\n",
      "Administrative           0.0  1.0\n",
      "Administrative_Duration  0.0  1.0\n",
      "Informational            0.0  1.0\n",
      "Informational_Duration   0.0  1.0\n",
      "ProductRelated           0.0  1.0\n",
      "ProductRelated_Duration  0.0  1.0\n",
      "BounceRates              0.0  1.0\n",
      "ExitRates                0.0  1.0\n",
      "PageValues               0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/pythonTutorial/online_raw.csv')\n",
    "dataset.fillna(dataset.mean(), inplace = True)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "#Define MinMaxScaler as scaler  \n",
    "scaler = MinMaxScaler()  \n",
    "#list all the feature that need to be scaled  \n",
    "scaling_column = ['Administrative','Administrative_Duration','Informational','Informational_Duration','ProductRelated','ProductRelated_Duration','BounceRates','ExitRates','PageValues']\n",
    "#Apply fit_transfrom to scale selected feature  \n",
    "dataset[scaling_column] = scaler.fit_transform(dataset[scaling_column])\n",
    "#Cheking min and max value of the scaling_column\n",
    "print(dataset[scaling_column].describe().T[['min','max']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64914fd9-acc8-43af-898e-8fa3621ab399",
   "metadata": {},
   "source": [
    "Data Pre-processing: Konversi string ke numerik\n",
    "---\n",
    "\n",
    "kita memiliki dua kolom yang bertipe object yang dinyatakan dalam tipe data str, yaitu kolom 'Month' dan 'VisitorType'. Karena setiap algoritma machine learning bekerja dengan menggunakan nilai numeris, maka kita perlu mengubah kolom dengan tipe pandas object atau str ini ke bertipe numeris. Untuk itu, kita list terlebih dahulu apa saja label unik di kedua kolom ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a3b660-6d38-426a-8187-db89f5cf13f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aug' 'Dec' 'Feb' 'Jul' 'June' 'Mar' 'May' 'Nov' 'Oct' 'Sep']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "['New_Visitor' 'Other' 'Returning_Visitor']\n",
      "[0 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yala\\AppData\\Local\\Temp/ipykernel_4052/363161620.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dataset.fillna(dataset.mean(), inplace = True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/pythonTutorial/online_raw.csv')\n",
    "dataset.fillna(dataset.mean(), inplace = True)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Convert feature/column 'Month'\n",
    "LE = LabelEncoder()\n",
    "dataset['Month'] = LE.fit_transform(dataset['Month'])\n",
    "print(LE.classes_)\n",
    "print(np.sort(dataset['Month'].unique()))\n",
    "print('')\n",
    "\n",
    "# Convert feature/column 'VisitorType'\n",
    "LE = LabelEncoder()\n",
    "dataset['VisitorType'] = LE.fit_transform(dataset['VisitorType'])\n",
    "print(LE.classes_)\n",
    "print(np.sort(dataset['VisitorType'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde08c3c-c0c8-454f-b84d-7c1a76b6fcbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
