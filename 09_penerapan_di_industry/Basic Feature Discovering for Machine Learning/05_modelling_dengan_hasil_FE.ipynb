{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06bfbf45-2d9f-4315-89ac-1bcd84355c66",
   "metadata": {},
   "source": [
    "Modelling dengan hasil Feature Engineering - Part 1\n",
    "--\n",
    "\n",
    "Karena di sini saya tidak akan membahas detil tentang Modelling part, mohon terima saja semuanya terlebih dahulu.\n",
    "\n",
    "Yang kita inginkan adalah menaikkan akurasi dari model kita dengan Feature Engineering.\n",
    "\n",
    "Pertanyaan nya apakah benar kita bisa menaikkan akurasi modelnya?\n",
    "\n",
    "Bagian ini akan menjawab hasilnya. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2808b49-d337-4e1a-9319-fe6b144caba2",
   "metadata": {},
   "source": [
    "- Perintah pertama bertujuan untuk membagi kembali dataset kita menjadi train dan test"
   ]
  },
  {
   "cell_type": "raw",
   "id": "306c2fd3-55e3-4a9f-b2cc-9fe5618ea1f8",
   "metadata": {},
   "source": [
    "df_train = df_all.loc[:890]\n",
    "df_test = df_all.loc[891:]\n",
    "dfs = [df_train, df_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdc2deb-62fd-418f-ab84-56718421e688",
   "metadata": {},
   "source": [
    "- Perintah kedua adalah LabelEncoder untuk data‚Äù yang bersifat non-numeric, tujuannya adalah melakukan encoding [0-n] untuk data kategorikal. Contohnya Sex, akan dirubah menjadi 0 dan 1, laki-laki dan perempuan."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3219bf9-7eed-43df-85b5-d843469bf7dc",
   "metadata": {},
   "source": [
    "non_numeric_features = ['Embarked', 'Sex', 'Title', 'Family_Size_Grouped', 'Age', 'Fare']\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in non_numeric_features:        \n",
    "        df[feature] = LabelEncoder().fit_transform(df[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4229f4a0-4704-4103-b605-3677dca8de11",
   "metadata": {},
   "source": [
    "- Perintah ketiga bertujuan untuk mengubah feature kategori menjadi one hot, dengan OneHotEncoder. Akan menghasilkan beberapa kolom tergantung banyaknya kategori.Contohnya Pclass akan menjadi 3 kolom Pclass_1, Pclass_2, dan Pclass_3. Isinya adalah 0 dan 1 tergantung kategori orang tersebut"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe5538b2-0cdd-4d27-b7bf-85e7c8eb1c57",
   "metadata": {},
   "source": [
    "cat_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'Family_Size_Grouped']\n",
    "encoded_features = []\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in cat_features:\n",
    "        encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()\n",
    "        n = df[feature].nunique()\n",
    "        cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n",
    "        encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n",
    "        encoded_df.index = df.index\n",
    "        encoded_features.append(encoded_df)\n",
    "\n",
    "df_train = pd.concat([df_train, *encoded_features[:5]], axis=1)\n",
    "df_test = pd.concat([df_test, *encoded_features[5:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec5172db-e74f-4115-b440-f81e43e8bd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yala\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "c:\\users\\yala\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "\n",
    "def concat_df(train_data, test_data):\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
    "\n",
    "df_train = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/challenge/feature-engineering/titanic_train.csv')\n",
    "df_test = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/challenge/feature-engineering/titanic_test.csv')\n",
    "df_all = concat_df(df_train, df_test)\n",
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set'\n",
    "\n",
    "age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\n",
    "df_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "df_all['Embarked'] = df_all['Embarked'].fillna('S')\n",
    "med_fare = df_all.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\n",
    "df_all['Fare'] = df_all['Fare'].fillna(med_fare)\n",
    "df_all['Fare'] = pd.qcut(df_all['Fare'], 13)\n",
    "df_all['Family_Size'] = df_all['SibSp'] + df_all['Parch'] + 1\n",
    "\n",
    "family_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\n",
    "df_all['Family_Size_Grouped'] = df_all['Family_Size'].map(family_map)\n",
    "df_all['Ticket_Frequency'] = df_all.groupby('Ticket')['Ticket'].transform('count')\n",
    "df_all['Title'] = df_all['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "df_all['Is_Married'] = 0\n",
    "df_all['Is_Married'].loc[df_all['Title'] == 'Mrs'] = 1\n",
    "df_all['Title'] = df_all['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\n",
    "df_all['Title'] = df_all['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')\n",
    "\n",
    "\n",
    "df_train = df_all.loc[:890]\n",
    "df_test = df_all.loc[891:]\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "non_numeric_features = ['Embarked', 'Sex', 'Title', 'Family_Size_Grouped', 'Age', 'Fare']\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in non_numeric_features:        \n",
    "        df[feature] = LabelEncoder().fit_transform(df[feature])\n",
    "        \n",
    "cat_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'Family_Size_Grouped']\n",
    "encoded_features = []\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in cat_features:\n",
    "        encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()\n",
    "        n = df[feature].nunique()\n",
    "        cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n",
    "        encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n",
    "        encoded_df.index = df.index\n",
    "        encoded_features.append(encoded_df)\n",
    "\n",
    "df_train = pd.concat([df_train, *encoded_features[:5]], axis=1)\n",
    "df_test = pd.concat([df_test, *encoded_features[5:]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a913664-ecd9-414c-bb0a-d1a024963d30",
   "metadata": {},
   "source": [
    "Modelling dengan hasil Feature Engineering - Part 2\n",
    "---\n",
    "\n",
    "Kita akan melakukan drop terhadap kolom-kolom yang tidak kita perlukan, atau yang sudah kita encode sebelumnya"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0be5b6d-2b5f-4def-8e6d-71db1ae727a7",
   "metadata": {},
   "source": [
    "df_all = concat_df(df_train, df_test)\n",
    "drop_cols = ['Cabin', 'Embarked', 'Survived', 'Name', 'PassengerId', 'Pclass', 'Sex', 'Ticket', 'Title']\n",
    "\n",
    "df_all.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb712af-a6e0-4218-b5ea-105d0e899a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yala\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age              Fare  Is_Married  Parch  SibSp  Ticket_Frequency\n",
      "0  22.0    (-0.001, 7.25]           0      0      1                 1\n",
      "1  38.0  (56.496, 83.475]           1      0      1                 2\n",
      "2  26.0     (7.896, 8.05]           0      0      0                 1\n",
      "3  35.0  (34.075, 56.496]           1      0      1                 2\n",
      "4  35.0     (7.896, 8.05]           0      0      0                 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "def concat_df(train_data, test_data):\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
    "\n",
    "df_train = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/challenge/feature-engineering/titanic_train.csv')\n",
    "df_test = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/challenge/feature-engineering/titanic_test.csv')\n",
    "df_all = concat_df(df_train, df_test)\n",
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set'\n",
    "\n",
    "age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\n",
    "df_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "df_all['Embarked'] = df_all['Embarked'].fillna('S')\n",
    "med_fare = df_all.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\n",
    "df_all['Fare'] = df_all['Fare'].fillna(med_fare)\n",
    "df_all['Fare'] = pd.qcut(df_all['Fare'], 13)\n",
    "df_all['Family_Size'] = df_all['SibSp'] + df_all['Parch'] + 1\n",
    "\n",
    "family_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\n",
    "df_all['Family_Size_Grouped'] = df_all['Family_Size'].map(family_map)\n",
    "df_all['Ticket_Frequency'] = df_all.groupby('Ticket')['Ticket'].transform('count')\n",
    "df_all['Title'] = df_all['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "df_all['Is_Married'] = 0\n",
    "df_all['Is_Married'].loc[df_all['Title'] == 'Mrs'] = 1\n",
    "df_all['Title'] = df_all['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\n",
    "df_all['Title'] = df_all['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')\n",
    "\n",
    "df_train = df_all.loc[:890]\n",
    "df_test = df_all.loc[891:]\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "# Silakan diketikkan kodenya di sini\n",
    "df_all = concat_df(df_train, df_test)\n",
    "drop_cols = ['Cabin', 'Embarked', 'Family_Size', 'Family_Size_Grouped', 'Survived',\n",
    "'Name', 'PassengerId', 'Pclass', 'Sex', 'Ticket', 'Title']\n",
    "\n",
    "df_all.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "print(df_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e1347d-dbf5-4e10-8097-e7fe65874001",
   "metadata": {},
   "source": [
    "Modelling dengan hasil Feature Engineering - Part 3\n",
    "--\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33b17d65-9c1d-48bd-8d21-09b67f39969f",
   "metadata": {},
   "source": [
    "X_train = StandardScaler().fit_transform(df_train.drop(columns=drop_cols))\n",
    "y_train = df_train['Survived'].values\n",
    "X_test = StandardScaler().fit_transform(df_test.drop(columns=drop_cols))\n",
    "\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12c346-9bb3-411f-ae8c-e3677f05ed8e",
   "metadata": {},
   "source": [
    "Setelah kita membagi train dan test untuk modelling seperti ini, kita akan melakukan modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74c487f2-32b7-4543-87b1-bfac9992a82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (891, 22)\n",
      "y_train shape: (891,)\n",
      "X_test shape: (418, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yala\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "c:\\users\\yala\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "\n",
    "def concat_df(train_data, test_data):\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
    "\n",
    "df_train = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/challenge/feature-engineering/titanic_train.csv')\n",
    "df_test = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/challenge/feature-engineering/titanic_test.csv')\n",
    "df_all = concat_df(df_train, df_test)\n",
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set'\n",
    "\n",
    "age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\n",
    "df_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "df_all['Embarked'] = df_all['Embarked'].fillna('S')\n",
    "med_fare = df_all.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\n",
    "df_all['Fare'] = df_all['Fare'].fillna(med_fare)\n",
    "df_all['Fare'] = pd.qcut(df_all['Fare'], 13)\n",
    "df_all['Family_Size'] = df_all['SibSp'] + df_all['Parch'] + 1\n",
    "\n",
    "family_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\n",
    "df_all['Family_Size_Grouped'] = df_all['Family_Size'].map(family_map)\n",
    "df_all['Ticket_Frequency'] = df_all.groupby('Ticket')['Ticket'].transform('count')\n",
    "df_all['Title'] = df_all['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "df_all['Is_Married'] = 0\n",
    "df_all['Is_Married'].loc[df_all['Title'] == 'Mrs'] = 1\n",
    "df_all['Title'] = df_all['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\n",
    "df_all['Title'] = df_all['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')\n",
    "\n",
    "df_train = df_all.loc[:890]\n",
    "df_test = df_all.loc[891:]\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "non_numeric_features = ['Embarked', 'Sex', 'Title', 'Family_Size_Grouped', 'Age', 'Fare']\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in non_numeric_features:        \n",
    "        df[feature] = LabelEncoder().fit_transform(df[feature])\n",
    "        \n",
    "cat_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'Family_Size_Grouped']\n",
    "encoded_features = []\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in cat_features:\n",
    "        encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()\n",
    "        n = df[feature].nunique()\n",
    "        cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n",
    "        encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n",
    "        encoded_df.index = df.index\n",
    "        encoded_features.append(encoded_df)\n",
    "\n",
    "df_train = pd.concat([df_train, *encoded_features[:5]], axis=1)\n",
    "df_test = pd.concat([df_test, *encoded_features[5:]], axis=1)\n",
    "drop_cols = ['Cabin', 'Embarked', 'Family_Size', 'Family_Size_Grouped', 'Survived',\n",
    "             'Name', 'PassengerId', 'Pclass', 'Sex', 'Ticket', 'Title']\n",
    "\n",
    "# Silakan ketikkan kodenya di sini\n",
    "X_train = StandardScaler().fit_transform(df_train.drop(columns=drop_cols))\n",
    "y_train = df_train['Survived'].values\n",
    "X_test = StandardScaler().fit_transform(df_test.drop(columns=drop_cols))\n",
    "\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379a9779-b1f0-4f76-9434-1cb5c70eddfb",
   "metadata": {},
   "source": [
    "Modelling dengan hasil Feature Engineering - Part 4\n",
    "--\n",
    "\n",
    "Kita akan menggunakan RandomForestClassifier dari SkLearn dan menghitung akurasi menggunakan cross_val_score"
   ]
  },
  {
   "cell_type": "raw",
   "id": "584e7c06-c68d-4bfd-99b2-0c1590083ab1",
   "metadata": {},
   "source": [
    "random_forest = RandomForestClassifier(criterion='gini', \n",
    "                                           n_estimators=1100,\n",
    "                                           max_depth=5,\n",
    "                                           min_samples_split=4,\n",
    "                                           min_samples_leaf=5,\n",
    "                                           max_features='auto',\n",
    "                                           oob_score=True,\n",
    "                                           random_state=50)\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49ddb792-355c-4888-a67c-7dd303dbc6c2",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(random_forest, X_train, y_train, cv=10, scoring = \"accuracy\")\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Mean:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc2989b7-5aef-4781-afb1-0d9a570d1121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yala\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "c:\\users\\yala\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.83333333 0.87640449 0.76404494 0.87640449 0.84269663 0.80898876\n",
      " 0.82022472 0.78651685 0.87640449 0.85393258]\n",
      "Mean: 0.8338951310861423\n",
      "Standard Deviation: 0.03719055862675359\n",
      "X_train shape: (891, 22)\n",
      "y_train shape: (891,)\n",
      "X_test shape: (418, 22)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def concat_df(train_data, test_data):\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
    "\n",
    "df_train = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/challenge/feature-engineering/titanic_train.csv')\n",
    "df_test = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/challenge/feature-engineering/titanic_test.csv')\n",
    "df_all = concat_df(df_train, df_test)\n",
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set'\n",
    "\n",
    "age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\n",
    "df_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "df_all['Embarked'] = df_all['Embarked'].fillna('S')\n",
    "med_fare = df_all.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\n",
    "df_all['Fare'] = df_all['Fare'].fillna(med_fare)\n",
    "df_all['Fare'] = pd.qcut(df_all['Fare'], 13)\n",
    "df_all['Family_Size'] = df_all['SibSp'] + df_all['Parch'] + 1\n",
    "\n",
    "family_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\n",
    "df_all['Family_Size_Grouped'] = df_all['Family_Size'].map(family_map)\n",
    "df_all['Ticket_Frequency'] = df_all.groupby('Ticket')['Ticket'].transform('count')\n",
    "df_all['Title'] = df_all['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "df_all['Is_Married'] = 0\n",
    "df_all['Is_Married'].loc[df_all['Title'] == 'Mrs'] = 1\n",
    "df_all['Title'] = df_all['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\n",
    "df_all['Title'] = df_all['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')\n",
    "\n",
    "df_train = df_all.loc[:890]\n",
    "df_test = df_all.loc[891:]\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "non_numeric_features = ['Embarked', 'Sex', 'Title', 'Family_Size_Grouped', 'Age', 'Fare']\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in non_numeric_features:        \n",
    "        df[feature] = LabelEncoder().fit_transform(df[feature])\n",
    "        \n",
    "cat_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'Family_Size_Grouped']\n",
    "encoded_features = []\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in cat_features:\n",
    "        encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()\n",
    "        n = df[feature].nunique()\n",
    "        cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n",
    "        encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n",
    "        encoded_df.index = df.index\n",
    "        encoded_features.append(encoded_df)\n",
    "\n",
    "df_train = pd.concat([df_train, *encoded_features[:5]], axis=1)\n",
    "df_test = pd.concat([df_test, *encoded_features[5:]], axis=1)\n",
    "drop_cols = ['Cabin', 'Embarked', 'Family_Size', 'Family_Size_Grouped', 'Survived',\n",
    "             'Name', 'PassengerId', 'Pclass', 'Sex', 'Ticket', 'Title']\n",
    "\n",
    "# Silakan ketikkan kodenya di sini\n",
    "X_train = StandardScaler().fit_transform(df_train.drop(columns=drop_cols))\n",
    "y_train = df_train['Survived'].values\n",
    "X_test = StandardScaler().fit_transform(df_test.drop(columns=drop_cols))\n",
    "\n",
    "random_forest = RandomForestClassifier(criterion='gini', \n",
    "                                           n_estimators=1100,\n",
    "                                           max_depth=5,\n",
    "                                           min_samples_split=4,\n",
    "                                           min_samples_leaf=5,\n",
    "                                           max_features='auto',\n",
    "                                           oob_score=True,\n",
    "                                           random_state=50)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(random_forest, X_train, y_train, cv=10, scoring = \"accuracy\")\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Mean:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())\n",
    "\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be0de48-f51c-45f0-b88a-af792d2fc4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
